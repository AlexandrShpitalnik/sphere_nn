{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from utils import create_dataloader\n",
    "from torchvision.utils import make_grid\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating config object (argparse workaround)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    pass\n",
    "\n",
    "config = Config()\n",
    "config.mnist_path = None\n",
    "config.batch_size = 16\n",
    "config.num_workers = 3\n",
    "config.num_epochs = 10\n",
    "config.noise_size = 50\n",
    "config.print_freq = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = create_dataloader(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3750"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, cat in dataloader:\n",
    "    break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "im = image.numpy()[0,0,:,:]\n",
    "im.resize(28*28)\n",
    "print(im.shape)\n",
    "im.resize(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa249a12190>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa29c1da110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(im, cmap=plt.cm.Greys_r)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.resize_(28*28)\n",
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential( \n",
    "            nn.Linear(config.noise_size, 200),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(200, 28*28),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(28*28, 200),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(200, 50),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(50, 1), \n",
    "            nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create optimizers and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_G = optim.Adam(params=generator.parameters(), lr=0.0001)\n",
    "optim_D = optim.Adam(params=discriminator.parameters(), lr=0.0001)\n",
    "\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create necessary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.FloatTensor(config.batch_size, 28*28))\n",
    "noise = Variable(torch.FloatTensor(config.batch_size, config.noise_size))\n",
    "fixed_noise = Variable(torch.FloatTensor(config.batch_size, config.noise_size).normal_(0, 1))\n",
    "label = Variable(torch.FloatTensor(config.batch_size))\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание\n",
    "\n",
    "1) Посмотрите на реализацию GAN\n",
    "\n",
    "2) Поменяйте ее, чтобы получился LSGAN https://arxiv.org/pdf/1611.04076v2.pdf\n",
    "\n",
    "3) Попробуйте оба GAN и LSGAN на CelebA http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html\n",
    "\n",
    "4) Напишите отчет что попробовали, какие результаты получили, как вам кажется надо обучать GAN, чтобы добиться сходимости?\n",
    "\n",
    "Обязательны графики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa24432b050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errDx_loss_epochs_global = []\n",
    "errDz_loss_epochs_global = []\n",
    "errG_loss_epochs_global = []\n",
    "\n",
    "for epoch in range(config.num_epochs):\n",
    "    \n",
    "    errDx_loss_epochs = []\n",
    "    errDz_loss_epochs = []\n",
    "    errG_loss_epochs = []\n",
    "    sample = None\n",
    "    \n",
    "    \n",
    "    for iteration, (images, cat) in enumerate(dataloader):\n",
    "        ####### \n",
    "        # Discriminator stage: maximize log(D(x)) + log(1 - D(G(z))) \n",
    "        #######\n",
    "        discriminator.zero_grad()\n",
    "        \n",
    "        # real\n",
    "        label.data.fill_(real_label)\n",
    "        input.data.copy_(images.resize_(28*28))\n",
    "        output = discriminator(input)\n",
    "        errD_x = criterion(output, label)\n",
    "        errDx_loss_epochs.append(errD_x.item())\n",
    "        errD_x.backward()\n",
    "        \n",
    "        # fake \n",
    "        noise.data.normal_(0, 1)\n",
    "        fake = generator(noise)\n",
    "        sample = fake\n",
    "        label.data.fill_(fake_label)\n",
    "        output = discriminator(fake.detach())\n",
    "        errD_z = criterion(output, label)\n",
    "        errDz_loss_epochs.append(errD_z.item())\n",
    "        errD_z.backward()\n",
    "        \n",
    "        optim_D.step()\n",
    "        \n",
    "        ####### \n",
    "        # Generator stage: maximize log(D(G(x))\n",
    "        #######\n",
    "        generator.zero_grad()\n",
    "        label.data.fill_(real_label)\n",
    "        output = discriminator(fake)\n",
    "        errG = criterion(output, label)\n",
    "        errG_loss_epochs.append(errG.item())\n",
    "        errG.backward()\n",
    "        \n",
    "        optim_G.step()\n",
    "        \n",
    "        \n",
    "        if (iteration+1) % config.print_freq == 0:\n",
    "            print('Epoch:{} Iter: {} errD_x: {:.2f} errD_z: {:.2f} errG: {:.2f}'.format(epoch+1,\n",
    "                                                                                            iteration+1, \n",
    "                                                                                            errD_x.data[0],\n",
    "                                                                                            errD_z.data[0], \n",
    "                                                                                        errG.data[0]))\n",
    "            \n",
    "    errDx_loss_epochs_global.append(np.mean(errDx_loss_epochs))        \n",
    "    errDz_loss_epochs_global.append(np.mean(errDz_loss_epochs))        \n",
    "    errG_loss_epochs_global.append(np.mean(errG_loss_epochs)) \n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        \n",
    "        clear_output(True)\n",
    "        #print('\\rEpoch {0}... (Train/Test) MSE: {1:.5f}/{2:.5f}'.format(\n",
    "        #                    epoch, train_loss_epochs[-1], test_loss_epochs[-1]))\n",
    "                    \n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(errDx_loss_epochs_global, label='errD_x')\n",
    "        plt.plot(errDz_loss_epochs_global, label='errD_z')\n",
    "        plt.plot(errG_loss_epochs_global, label='errG')\n",
    "        plt.xlabel('Epochs', fontsize=16)\n",
    "        plt.ylabel('Loss', fontsize=16)\n",
    "        plt.legend(loc=0, fontsize=16)\n",
    "        plt.grid()\n",
    "                    \n",
    "            \n",
    "        plt.subplot(1, 2, 2)\n",
    "        im = fake.detach().numpy()[0]\n",
    "        im.resize(28,28)\n",
    "        plt.imshow(im, cmap=plt.cm.Greys_r)\n",
    "        plt.show()                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#хак - заморозка на время генератора/дискриминатора, пока они не сравняются по функции потерь "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "print_freq = 10\n",
    "batch_size = 10\n",
    "noise_size = 100\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential( \n",
    "            \n",
    "            nn.ConvTranspose2d(100, 256, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.ConvTranspose2d(64, 28, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.ConvTranspose2d(28, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
    "            nn.Tanh()\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), x.size(1), 1, 1)\n",
    "        return self.model(x)\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 28, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.Conv2d(28, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = self.model(x).squeeze()\n",
    "        res = res.view(res.size(0))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_G = optim.Adam(params=generator.parameters(), lr=0.0001)\n",
    "optim_D = optim.Adam(params=discriminator.parameters(), lr=0.0001)\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.FloatTensor(batch_size, 28*28))\n",
    "noise = Variable(torch.FloatTensor(batch_size, noise_size))\n",
    "fixed_noise = Variable(torch.FloatTensor(batch_size, noise_size).normal_(0, 1))\n",
    "label = Variable(torch.FloatTensor(batch_size))\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "c_label = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (1 x 1). Kernel size: (4 x 4). Kernel size can't be greater than actual input size at /opt/conda/conda-bld/pytorch_1535488076166/work/aten/src/THNN/generic/SpatialConvolutionMM.c:48",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-82ae540951c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#input.data.copy_(images.resize_(28*28))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0merrD_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0merrDx_loss_epochs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrD_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-a4e72335985d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/torch/nn/modules/container.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/torch/nn/modules/conv.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (1 x 1). Kernel size: (4 x 4). Kernel size can't be greater than actual input size at /opt/conda/conda-bld/pytorch_1535488076166/work/aten/src/THNN/generic/SpatialConvolutionMM.c:48"
     ]
    }
   ],
   "source": [
    "errDx_loss_epochs_global = []\n",
    "errDz_loss_epochs_global = []\n",
    "errG_loss_epochs_global = []\n",
    "\n",
    "for epoch in range(100):#config.num_epochs):\n",
    "    \n",
    "    errDx_loss_epochs = []\n",
    "    errDz_loss_epochs = []\n",
    "    errG_loss_epochs = []\n",
    "    sample = None\n",
    "    \n",
    "    \n",
    "    for iteration, (images, cat) in enumerate(dataloader):\n",
    "        ####### \n",
    "        # Discriminator stage: maximize log(D(x)) + log(1 - D(G(z))) \n",
    "        #######\n",
    "        discriminator.zero_grad()\n",
    "        \n",
    "        # real\n",
    "        label.data.fill_(real_label)\n",
    "        #input.data.copy_(images.resize_(28*28))\n",
    "        output = discriminator(images)\n",
    "        errD_x = criterion(output, label)\n",
    "        errDx_loss_epochs.append(errD_x.item())\n",
    "        errD_x.backward()\n",
    "        \n",
    "        \n",
    "        # fake \n",
    "        noise.data.normal_(-1, 1)\n",
    "        fake = generator(noise)\n",
    "        sample = fake[0]\n",
    "        label.data.fill_(fake_label)\n",
    "        output = discriminator(fake.detach())\n",
    "        errD_z = criterion(output, label)\n",
    "        errDz_loss_epochs.append(errD_z.item())\n",
    "        errD_z.backward()\n",
    "        \n",
    "        optim_D.step()\n",
    "        \n",
    "        ####### \n",
    "        # Generator stage: maximize log(D(G(x))\n",
    "        #######\n",
    "        generator.zero_grad()\n",
    "        label.data.fill_(c_label)\n",
    "        output = discriminator(fake)\n",
    "        errG = criterion(output, label)\n",
    "        errG_loss_epochs.append(errG.item())\n",
    "        errG.backward()\n",
    "        \n",
    "        optim_G.step() \n",
    "        \n",
    "      \n",
    "        \n",
    "        if (iteration+1) % print_freq == 0:\n",
    "            print('Epoch:{} Iter: {} errD_x: {:.5f} errD_z: {:.5f} errG: {:.5f}'.format(epoch+1,\n",
    "                                                                                            iteration+1, \n",
    "                                                                                            errD_x.data[0],\n",
    "                                                                                            errD_z.data[0], \n",
    "                                                                                        errG.data[0]))\n",
    "            \n",
    "    errDx_loss_epochs_global.append(np.mean(errDx_loss_epochs))        \n",
    "    errDz_loss_epochs_global.append(np.mean(errDz_loss_epochs))        \n",
    "    errG_loss_epochs_global.append(np.mean(errG_loss_epochs)) \n",
    "    #im = (fake.detach().numpy()[0]).reshape(64,64, 3 )\n",
    "    #print im.shape\n",
    "    #im.resize(6,28)\n",
    "    plt.imshow(denorm(sample.permute(1, 2, 0).detach()).numpy())\n",
    "    #plt.imshow(im, cmap=plt.cm.Greys_r\n",
    "    plt.show()\n",
    "    if epoch % 1 == 0:\n",
    "        pass\n",
    "        #clear_output(True)\n",
    "        #print('\\rEpoch {0}... (Train/Test) MSE: {1:.5f}/{2:.5f}'.format(\n",
    "        #                    epoch, train_loss_epochs[-1], test_loss_epochs[-1]))\n",
    "                    \n",
    "        #plt.figure(figsize=(12, 5))\n",
    "        #plt.subplot(1, 2, 1)\n",
    "        #plt.plot(train_loss_epochs, label='Train')\n",
    "        #plt.plot(train_loss_epochs, label='Train')\n",
    "        #plt.plot(test_loss_epochs, label='Test')\n",
    "        #plt.xlabel('Epochs', fontsize=16)\n",
    "        #plt.ylabel('Loss', fontsize=16)\n",
    "        #plt.legend(loc=0, fontsize=16)\n",
    "        #plt.grid()\n",
    "                    \n",
    "        #true, predicted = self.predict()        \n",
    "        #plt.subplot(1, 2, 2)\n",
    "        #plt.plot(true, label='True')\n",
    "        #plt.plot(predicted, label='Prediction')\n",
    "        #plt.legend()\n",
    "        #plt.grid() \n",
    "        #plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "Epoch:1 Iter: 100 errD_x: 0.49 errD_z: 0.67 errG: 0.73\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:62: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/alex/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:63: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/alex/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:64: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "Epoch:1 Iter: 200 errD_x: 0.63 errD_z: 0.65 errG: 0.75\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-61:\n",
      "Process Process-63:\n",
      "Process Process-62:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alex/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/home/alex/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "  File \"/home/alex/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/alex/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/home/alex/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alex/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "  File \"/home/alex/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "    self.run()\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/alex/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 131, in get\n",
      "  File \"/home/alex/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 131, in get\n",
      "  File \"/home/alex/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    if not self._poll(timeout):\n",
      "    if not self._poll(timeout):\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alex/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/alex/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 131, in get\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "KeyboardInterrupt\n",
      "    if not self._poll(timeout):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/alex/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/alex/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/alex/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 376, in _fixed_getinnerframes\n",
      "    lines = ulinecache.getlines(file)[start:end]\n",
      "  File \"/home/alex/anaconda2/lib/python2.7/site-packages/IPython/utils/ulinecache.py\", line 37, in getlines\n",
      "    return [l.decode(encoding, 'replace') for l in lines]\n",
      "  File \"/home/alex/anaconda2/lib/python2.7/encodings/utf_8.py\", line 15, in decode\n",
      "    def decode(input, errors='strict'):\n",
      "  File \"/home/alex/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 11177) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1824\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1826\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1412\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1320\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m             )\n\u001b[1;32m   1322\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m             \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructured_traceback_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "errDx_loss_epochs_global = []\n",
    "errDz_loss_epochs_global = []\n",
    "errG_loss_epochs_global = []\n",
    "\n",
    "for epoch in range(config.num_epochs):\n",
    "    \n",
    "    errDx_loss = [0]\n",
    "    errDz_loss = [0]\n",
    "    errG_loss = [0]\n",
    "    sample = None\n",
    "    \n",
    "    \n",
    "    for iteration, (images, cat) in enumerate(dataloader):\n",
    "        ####### \n",
    "        # Discriminator stage: maximize log(D(x)) + log(1 - D(G(z))) \n",
    "        #######\n",
    "        discriminator.zero_grad()\n",
    "        \n",
    "        # real\n",
    "        label.data.fill_(real_label)\n",
    "        input.data.copy_(images.resize_(28*28))\n",
    "        output = discriminator(input)\n",
    "        errD_x = criterion(output, label)\n",
    "        errDx_loss.append(errD_x.item())\n",
    "        if errDx_loss[-1] + 0.1 > errG_loss[-1]:\n",
    "            errD_x.backward()\n",
    "            optim_D.step()\n",
    "        \n",
    "        \n",
    "        # fake \n",
    "        noise.data.normal_(0, 1)\n",
    "        fake = generator(noise)\n",
    "        sample = fake\n",
    "        label.data.fill_(fake_label)\n",
    "        output = discriminator(fake.detach())\n",
    "        errD_z = criterion(output, label)\n",
    "        errDz_loss.append(errD_z.item())\n",
    "        if errDz_loss[-1] + 0.1 > errG_loss[-1]:\n",
    "            errD_z.backward()\n",
    "            optim_D.step()\n",
    "        \n",
    "        \n",
    "        ####### \n",
    "        # Generator stage: maximize log(D(G(x))\n",
    "        #######\n",
    "        generator.zero_grad()\n",
    "        label.data.fill_(real_label)\n",
    "        output = discriminator(fake)\n",
    "        errG = criterion(output, label)\n",
    "        errG_loss.append(errG.item())\n",
    "        #if errG_loss[-1] + 0.1 > errDz_loss[-1] or errG_loss[-1] + 0.1 > errDx_loss[-1]:\n",
    "        errG.backward()\n",
    "        optim_G.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        if (iteration+1) % config.print_freq == 0:\n",
    "            print('Epoch:{} Iter: {} errD_x: {:.2f} errD_z: {:.2f} errG: {:.2f}'.format(epoch+1,\n",
    "                                                                                            iteration+1, \n",
    "                                                                                            errD_x.data[0],\n",
    "                                                                                            errD_z.data[0], \n",
    "                                                                                        errG.data[0]))\n",
    "            \n",
    "    errDx_loss_epochs_global.append(np.mean(errDx_loss))        \n",
    "    errDz_loss_epochs_global.append(np.mean(errDz_loss))        \n",
    "    errG_loss_epochs_global.append(np.mean(errG_loss)) \n",
    "    im = fake.detach().numpy()[0]\n",
    "    im.resize(28,28)\n",
    "    plt.imshow(im, cmap=plt.cm.Greys_r)\n",
    "    plt.show()\n",
    "    if epoch % 1 == 0:\n",
    "        pass\n",
    "        #clear_output(True)\n",
    "        #print('\\rEpoch {0}... (Train/Test) MSE: {1:.5f}/{2:.5f}'.format(\n",
    "        #                    epoch, train_loss_epochs[-1], test_loss_epochs[-1]))\n",
    "                    \n",
    "        #plt.figure(figsize=(12, 5))\n",
    "        #plt.subplot(1, 2, 1)\n",
    "        #plt.plot(train_loss_epochs, label='Train')\n",
    "        #plt.plot(train_loss_epochs, label='Train')\n",
    "        #plt.plot(test_loss_epochs, label='Test')\n",
    "        #plt.xlabel('Epochs', fontsize=16)\n",
    "        #plt.ylabel('Loss', fontsize=16)\n",
    "        #plt.legend(loc=0, fontsize=16)\n",
    "        #plt.grid()\n",
    "                    \n",
    "        #true, predicted = self.predict()        \n",
    "        #plt.subplot(1, 2, 2)\n",
    "        #plt.plot(true, label='True')\n",
    "        #plt.plot(predicted, label='Prediction')\n",
    "        #plt.legend()\n",
    "        #plt.grid() \n",
    "        #plt.show()                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "\n",
    "class LSGAN_D_Loss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LSGAN_D_Loss,self).__init__()\n",
    "    \n",
    "    def forward(self,pred,true):\n",
    "        res = torch.sum((pred - true)**2)/(pred.shape[0]*2)\n",
    "        return res\n",
    "\n",
    "    \n",
    "class LSGAN_G_Loss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LSGAN_G_Loss,self).__init__()\n",
    "    \n",
    "    def forward(self,pred,true):\n",
    "        res = torch.sum((pred - true)**2)/(pred.shape[0]*2)\n",
    "        return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = 'img_ds'\n",
    "image_size = 64\n",
    "print_freq = 10\n",
    "batch_size = 1000\n",
    "noise_size = 100\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Scale(image_size),\n",
    "    #transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(IMAGE_PATH, transform)\n",
    "\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential( \n",
    "            \n",
    "            nn.ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
    "            ##еще 2 deconv stride = (1,1)\n",
    "            ##\n",
    "            \n",
    "            nn.Tanh()\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), x.size(1), 1, 1)\n",
    "        return self.model(x)\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = self.model(x).squeeze()\n",
    "        res = res.view(res.size(0))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_G = optim.Adam(params=generator.parameters(), lr=0.0001)\n",
    "optim_D = optim.Adam(params=discriminator.parameters(), lr=0.0001)\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = Variable(torch.FloatTensor(batch_size, noise_size))\n",
    "fixed_noise = Variable(torch.FloatTensor(batch_size, noise_size).normal_(0, 1))\n",
    "label = Variable(torch.FloatTensor(batch_size))\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "c_label = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errDx_loss_epochs_global = []\n",
    "errDz_loss_epochs_global = []\n",
    "errG_loss_epochs_global = []\n",
    "\n",
    "for epoch in range(2):#config.num_epochs):\n",
    "    \n",
    "    errDx_loss_epochs = []\n",
    "    errDz_loss_epochs = []\n",
    "    errG_loss_epochs = []\n",
    "    sample = None\n",
    "    \n",
    "    \n",
    "    for iteration, (images, cat) in enumerate(data_loader):\n",
    "        \n",
    "        bs = images.shape[0]\n",
    "        \n",
    "        noise = Variable(torch.FloatTensor(bs, noise_size))\n",
    "        fixed_noise = Variable(torch.FloatTensor(bs, noise_size).normal_(0, 1))\n",
    "        label = Variable(torch.FloatTensor(bs))\n",
    "        ####### \n",
    "        # Discriminator stage: maximize log(D(x)) + log(1 - D(G(z))) \n",
    "        #######\n",
    "        discriminator.zero_grad()\n",
    "        \n",
    "        # real\n",
    "        label.data.fill_(real_label)\n",
    "        output = discriminator(images)\n",
    "        errD_x = criterion(output, label)\n",
    "        errDx_loss_epochs.append(errD_x.item())\n",
    "        errD_x.backward()\n",
    "        \n",
    "        \n",
    "        # fake \n",
    "        noise.data.normal_(-1, 1)\n",
    "        fake = generator(noise)\n",
    "        sample = fake[0]\n",
    "        label.data.fill_(fake_label)\n",
    "        output = discriminator(fake.detach())\n",
    "        errD_z = criterion(output, label)\n",
    "        errDz_loss_epochs.append(errD_z.item())\n",
    "        errD_z.backward()\n",
    "        \n",
    "        optim_D.step()\n",
    "        \n",
    "        ####### \n",
    "        # Generator stage: maximize log(D(G(x))\n",
    "        #######\n",
    "        generator.zero_grad()\n",
    "        label.data.fill_(c_label)\n",
    "        output = discriminator(fake)\n",
    "        errG = criterion(output, label)\n",
    "        errG_loss_epochs.append(errG.item())\n",
    "        errG.backward()\n",
    "        \n",
    "        optim_G.step() \n",
    "        \n",
    "      \n",
    "        \n",
    "        if (iteration+1) % 1 == 0:\n",
    "            print('Epoch:{} Iter: {} errD_x: {:.5f} errD_z: {:.5f} errG: {:.5f}'.format(epoch+1,\n",
    "                                                                                            iteration+1, \n",
    "                                                                                            errD_x.data[0],\n",
    "                                                                                            errD_z.data[0], \n",
    "                                                                                        errG.data[0]))\n",
    "            \n",
    "    errDx_loss_epochs_global.append(np.mean(errDx_loss_epochs))        \n",
    "    errDz_loss_epochs_global.append(np.mean(errDz_loss_epochs))        \n",
    "    errG_loss_epochs_global.append(np.mean(errG_loss_epochs)) \n",
    "    \n",
    "\n",
    "    clear_output(True)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(errDx_loss_epochs_global, label='errD_x')\n",
    "    plt.plot(errDz_loss_epochs_global, label='errD_z')\n",
    "    plt.plot(errG_loss_epochs_global, label='errG')\n",
    "    plt.xlabel('Epochs', fontsize=16)\n",
    "    plt.ylabel('Loss', fontsize=16)\n",
    "    plt.legend(loc=0, fontsize=16)\n",
    "    plt.grid()\n",
    "                    \n",
    "            \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(denorm(sample.permute(1, 2, 0).detach()).numpy())\n",
    "    plt.show()                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
